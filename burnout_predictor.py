# -*- coding: utf-8 -*-
"""Burnout_predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CoZtfSUGK4p3Q4ddTDw16QwX2o4Y2EP_

# Task
Build a machine learning model to predict burnout rate using the data from "/content/train.csv" and "/content/test.csv", and save the trained model as a .pkl file.

## Load data

### Subtask:
Load the training and testing data from the provided CSV files into pandas DataFrames.

**Reasoning**:
Load the training and testing data into pandas DataFrames and display the first few rows of each.
"""

import pandas as pd

train_df = pd.read_csv('/content/train.csv')
test_df = pd.read_csv('/content/test.csv')

display(train_df.head())
display(test_df.head())

"""## Preprocess data

### Subtask:
Handle missing values, encode categorical features, and scale numerical features as necessary.

**Reasoning**:
Identify and handle missing values in both the training and testing DataFrames, convert 'Date of Joining' to datetime objects, extract relevant features, and encode categorical features.
"""

print("Missing values in train_df:")
print(train_df.isnull().sum())
print("\nMissing values in test_df:")
print(test_df.isnull().sum())

train_df['Date of Joining'] = pd.to_datetime(train_df['Date of Joining'])
test_df['Date of Joining'] = pd.to_datetime(test_df['Date of Joining'])

train_df['join_year'] = train_df['Date of Joining'].dt.year
train_df['join_month'] = train_df['Date of Joining'].dt.month
train_df['join_day'] = train_df['Date of Joining'].dt.day

test_df['join_year'] = test_df['Date of Joining'].dt.year
test_df['join_month'] = test_df['Date of Joining'].dt.month
test_df['join_day'] = test_df['Date of Joining'].dt.day

train_df = train_df.drop('Date of Joining', axis=1)
test_df = test_df.drop('Date of Joining', axis=1)

categorical_cols = ['Gender', 'Company Type', 'WFH Setup Available']
train_df = pd.get_dummies(train_df, columns=categorical_cols, drop_first=True)
test_df = pd.get_dummies(test_df, columns=categorical_cols, drop_first=True)

print("\nTrain_df after processing:")
display(train_df.head())
print("\nTest_df after processing:")
display(test_df.head())

"""**Reasoning**:

1.   List item
2.   List item


Impute the missing values in the training DataFrame using the mean of the respective columns.


"""

train_df.fillna({
    'Resource Allocation': train_df['Resource Allocation'].mean(),
    'Mental Fatigue Score': train_df['Mental Fatigue Score'].mean(),
    'Burn Rate': train_df['Burn Rate'].mean()
}, inplace=True)
print("Missing values in train_df after imputation:")
print(train_df.isnull().sum())

"""## Feature engineering

### Subtask:
Create new features that could improve model performance, if needed.

**Reasoning**:
Create interaction features by multiplying 'Resource Allocation' and 'Mental Fatigue Score', as these are likely to influence burnout rate together.
"""

train_df['resource_fatigue_interaction'] = train_df['Resource Allocation'] * train_df['Mental Fatigue Score']
test_df['resource_fatigue_interaction'] = test_df['Resource Allocation'] * test_df['Mental Fatigue Score']

display(train_df.head())
display(test_df.head())

"""## Model selection and training

### Subtask:
Choose an appropriate machine learning model for predicting burnout rate and train it using the preprocessed training data.

**Reasoning**:
Import RandomForestRegressor, define features and target, instantiate and train the model.
"""

from sklearn.ensemble import RandomForestRegressor

X_train = train_df.drop(['Employee ID', 'Burn Rate'], axis=1)
y_train = train_df['Burn Rate']

model = RandomForestRegressor(random_state=42)

model.fit(X_train, y_train)

"""## Model evaluation

### Subtask:
Evaluate the trained model's performance on the testing data using relevant metrics.

**Reasoning**:
Make predictions on the test data and then state that direct evaluation is not possible without the target variable in the test set, mentioning appropriate metrics if a validation set were available.
"""

X_test = test_df.drop('Employee ID', axis=1)
predictions = model.predict(X_test)

print("Model training complete and predictions made on the test set.")
print("Direct evaluation using metrics like R-squared or Mean Absolute Error is not possible with the provided test set alone as it does not contain the target variable ('Burn Rate').")
print("If a separate validation set with known 'Burn Rate' values were available, appropriate evaluation metrics would include Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared.")

"""## Save model

### Subtask:
Save the trained model in `.pkl` format for later use.

**Reasoning**:
Save the trained model to a file using joblib.
"""

import joblib

joblib.dump(model, 'burnout_prediction_model.pkl')

"""## Summary:

### Data Analysis Key Findings

*   The training data had missing values in 'Resource Allocation', 'Mental Fatigue Score', and 'Burn Rate', while the test data had no missing values.
*   Missing values in the training data's numerical columns were imputed using the mean of their respective columns.
*   Categorical features ('Gender', 'Company Type', and 'WFH Setup Available') were successfully one-hot encoded in both datasets.
*   New features, year, month, and day, were extracted from the 'Date of Joining' column, and the original column was dropped.
*   An interaction feature named 'resource\_fatigue\_interaction' was created by multiplying 'Resource Allocation' and 'Mental Fatigue Score'.
*   A `RandomForestRegressor` model was trained using the processed training data.
*   The trained model was used to make predictions on the test set.
*   The trained model was saved to a file named `burnout_prediction_model.pkl`.

### Insights or Next Steps

*   Direct evaluation of the model's performance on the provided test set was not possible as it lacks the target variable ('Burn Rate').
*   To properly evaluate the model's performance, a validation set with known target values would be required, allowing for the calculation of metrics like MAE, MSE, and R-squared.

"""